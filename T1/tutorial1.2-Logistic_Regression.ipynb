{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../3600.jpg\" width=500 />\n",
    "\n",
    "# Tutorial 1 Part 2: Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this tutorial, we will cover:\n",
    "\n",
    "* Basics of supervised learning\n",
    "    - Definitions\n",
    "    - Optimizing with SGD\n",
    "    - Types of errors\n",
    "* Classic ML example: Binary logistic regression from scratch using numpy\n",
    "* Multiclass logistic regression from scratch with PyTorch and autograd\n",
    "    - Optimization\n",
    "    - Writing training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Theory Reminders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The supervised learning framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. `Labeled dataset` of $N$ labelled samples: $\\mathcal{S} = \\{ (\\vec{x_i},y_i) \\}_{i=1}^N$, where:\n",
    "- $\\vec{x_i} = \\left(x_i^1, \\dots, x_i^D\\right) \\in \\mathcal{X}$  is a **sample** or **feature vector**.\n",
    "- $y_i \\in \\mathcal{Y}$ is the **label**.\n",
    "- For classification with $C$ classes, $\\mathcal{Y} = \\{0,\\dots,C-1\\}$, so each $y_i$ is a **class label**.\n",
    "- Probabilistic perspective: assume each labeled sample $(\\vec{x}^i,y^i)\\sim\\mathcal{D}$,\n",
    "  i.e. each labeled sample is drawn from a joint distribution $\\mathcal{D}$ over $\\mathcal{X}\\times\\mathcal{Y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2. `model` is a parametrized set of functions $\\mathcal{H}\\subseteq \\mathcal{Y}^{\\mathcal{X}}$.\n",
    "($\\mathcal{Y}^{\\mathcal{X}}$ is the set of all functions from $\\mathcal{X}$ to $\\mathcal{Y}$).\n",
    "\n",
    "From a probabilistic perspective, a model is a posterior: $P_{Y|\\vec{X}}(y, \\vec{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, the following hypothesis class\n",
    "\n",
    "$$\n",
    "\\mathcal{H} =\n",
    "\\left\\{ h: \\mathcal{X}\\rightarrow\\mathcal{Y}\n",
    "~\\vert~\n",
    "h(\\vec{x}) = \\varphi(\\vec{w}\\vec{x}+b); \\vec{w}\\in\\set{R}^D,~b\\in\\set{R}\\right\\}\n",
    "$$\n",
    "where $\\varphi(\\cdot)$ is some nonlinear function, is known as the **perceptron** model.\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/2100/1*n6sJ4yZQzwKL9wnF5wnVNg.png\" width=700 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3. `pointwise loss function` is $\\ell:\\mathcal{Y}\\times\\mathcal{Y}\\to{R}$\n",
    "if and only if it satisfies the following four conditions:\n",
    "- Non-negativity: $\\ell(y_i, y_j) ≥ 0$, for any two distinct observations i,j.\n",
    "- Symmetry: $\\ell(y_i, y_j) = \\ell(y_j, y_i)$ for all p and q.\n",
    "- Triangle Inequality: $\\ell(y_i, y_j) ≤ \\ell(y_i, y_k) + \\ell(y_k, y_j)$ for all i,j,k.\n",
    "\n",
    "\n",
    "Regression Loss Functions such as **Mean Squared Error** (MSE), **Log MSE** etc.. \n",
    "\n",
    "Binary Classification Loss Functions such as **Binary Cross-Entropy**, **Hinge** etc..\n",
    "\n",
    "Multi-Class Classification Loss Functions such as **Multi-Class Cross-Entropy**, **Kullback Leibler Divergence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**The task**: Given the training set $\\mathcal{S} = \\{ (\\vec{x}^i,y^i) \\}_{i=1}^N \\sim \\mathcal{D}$, find \n",
    "a predictor (hypothesis) $h: \\mathcal{X}\\to\\mathcal{Y}$ which minimizes **population loss**:\n",
    "\n",
    "$$\n",
    "L_{\\mathcal{D}}(h) =  E[(\\vec{x},y)\\sim\\mathcal{D}]{\\ell(y, h(\\vec{x})}.\n",
    "$$\n",
    "\n",
    "This is also known as the **out-of-sample** loss. It is a deterministic quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can we solve this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Joint-distribution $\\mathcal{D}$ is unknown!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Instead, we define an **empirical (in-sample) loss** $L_{\\mathcal{S}}(h)$ as the measure of how well a function $h\\in\\mathcal{H}$ fits the data $\\mathcal{S}$, for example\n",
    "$$\n",
    "L_{\\mathcal{S}}(h) = \\frac{1}{N} \\sum_{i=1}^{N} \\ell(h(\\vec{x}^i), y^i) + R(h)\n",
    "$$\n",
    "where\n",
    "\n",
    "- $\\ell(y,\\hat{y})$ is some pointwise loss (depends on the data).\n",
    "- $R(h)$ is a regularization term (depends only on the model).\n",
    "\n",
    "Note that the in-sample loss is a random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, minimizing the empirical loss might not give us the best outcome, since our dataset can be [imbalanced](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data?fbclid=IwAR1v65XxQcl_3lb9kSh5WWs_-TWad4tyGoc_kWUP6eHxoI4m7JXeHLqAaFc)\n",
    "or we can have other desires such as [fairness](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing),\n",
    "or low false positive rate \n",
    "<center><img src=\"https://img-9gag-fun.9cache.com/photo/aRVbMvy_700bwp.webp\" width=\"700\"/></center>\n",
    "\n",
    "\n",
    "\n",
    "and many more\n",
    "\n",
    "*note that if we have time in the end of this tutorial i will dive deeper into some of this intresting topics*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The model is **trained** by updating it's parameters to improve its performance on some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We wish to find a parametrization $\\vec{w}^\\ast$ of our model $h^{\\ast}_{\\mathcal{S}}(\\vec{x};\\vec{w}^\\ast)\\in\\mathcal{H}$ such that\n",
    "$$\n",
    "h^{\\ast}_{\\mathcal{S}} = \\arg\\min_{h\\in\\mathcal{H}} L_{\\mathcal{S}}(h)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Usual approach: descent-based optimization (will be covered in next lecture)\n",
    "$$\n",
    "\\vec{w}_{k+1} \\leftarrow \\vec{w}_{k} - \\eta \\vec{d}_{k}\n",
    "$$\n",
    "\n",
    "Where $\\vec{d}_k$ is a **descent direction** and $\\eta$ is the step size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Most common choice for $\\vec{d}_k$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gradient descent: $\\vec{d}_k = \\nabla_{\\vec{w}_{k}} L(\\vec{w}_{k})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Will we find the solution, $\\vec{w}^\\ast$, though?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Generally the loss is non-convex and we have no guarantee of converging to the global optimum!\n",
    "$\\Rightarrow$ **Optimization Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://blog.paperspace.com/content/images/2019/09/F1-02.large.jpg\" width=800 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Gradient descent (GD) has the advantage of being extremely simple to apply, and requires only first-order derivatives.\n",
    "\n",
    "However it provides no guarantees for convergence on non-convex objectives.\n",
    "\n",
    "Later in the course we'll learn about variants of GD which perform well in practice even on the non-convex objectives we'll face in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Generalization and Expressiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We've talked about optimization error.\n",
    "\n",
    "What are **other** sources of errors in our learning approach (besides optimization)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We train to minimize our empirical loss $L_\\mathcal{S}$ instead of the population loss $L_\\mathcal{D}$ $\\Rightarrow$ **Generalization Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We only consider a limited set of possible functions, $\\mathcal{H}$ $\\Rightarrow$ **Approximation Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/error_types.png\" width=800 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How do we mitigate these errors in the practice of machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Optimization error: Mini batches; GD variants like stochastic gradient, momentum, Adam, etc (we'll see later in the course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Generalization error: Get more data; get data which better represents $\\mathcal{D}$; train-test splits; cross validation; early stopping; regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Approximation error: Use a powerful hypothesis class (e.g. DNN); more parameters; tailoring to the domain (e.g. CNN for images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binary Logistic Regression\n",
    "\n",
    "Actually a **classification** model. We're trying to classify data into 2 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Domain: $\\vec{x}^i \\in {R}^D$\n",
    "- Target: $y^i \\in \\{0,1\\}$\n",
    "- Model: $\\hat{y} = h(\\vec{x}) = \\sigma(\\vectr{w}\\vec{x}+b)$, where $\\sigma(\\vec{z})$ is the **logistic function**:\n",
    "    $$\\sigma(\\vec{z}) = \\frac{1}{1+e^{-\\vec{z}}}.$$\n",
    "    This function maps the real line onto $[0,1]$.\n",
    "- Probabilistic interpretation: $\\hat{y}=P(\\rvar{Y}=1|\\rvec{X}=\\vec{x})$.\n",
    "\n",
    "  This is a posterior probability function for our target variable $\\rvar{Y}$.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logistic(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "x = np.arange(-5, 5, .01)\n",
    "y_hat = logistic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y_hat, label='$\\sigma(z)$')\n",
    "plt.grid(True); plt.xlabel('z'); plt.legend(); plt.title('The logistic function');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To optimize, we minimize the **negative log-likelihood** (equivalent to maximizing likelihood, i.e. MLE) of the parameters $\\vec{w}$:\n",
    "\n",
    "$$\n",
    "\\bb{w}^\\ast = \\mathrm{arg}\\max_{ \\bb{w}} \\prod_{i=1}^n P(y_i | \\bb{x}_i;\\vec{w}) = \\mathrm{arg}\\min_{ \\bb{w}} \\sum_{i=1}^n -\\log P(y_i | \\bb{x}_i; \\vec{w})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Based on this we define our loss $L({w})$ (what we minimize) as,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L({w}) &\\triangleq \\sum_{i=1}^n -\\log P(y_i | \\bb{x}_i)\\\\\n",
    "&= \\sum_{i=1}^n -y_i \\log P(y_i=1 | \\bb{x}_i) - (1-y_i) \\log P(y_i=0 | \\bb{x}_i) \\\\\n",
    "&= \\sum_{i=1}^n -y_i \\log \\hat{y}_i - (1-y_i) \\log(1-\\hat{y}_i)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The resulting pointwise loss is also known as **cross-entropy**:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\ell(y, \\hat{y}) &=  - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y}) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "(The \"cross\" here is between the distribution of the samples $y^i$ and the distribution of the predictions $\\hat{y}^i$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Optimization scheme: No closed form solution, but loss is **convex** so gradient-based approach leads to global optimum.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\ell(y, \\hat{y}) &=  - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y}) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Let's plot this loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_y0 = -np.log(1-y_hat)\n",
    "loss_y1 = -np.log(y_hat)\n",
    "plt.plot(y_hat, loss_y0, label='$\\ell(y=0,\\hat{y})$')\n",
    "plt.plot(y_hat, loss_y1, label='$\\ell(y=1,\\hat{y})$')\n",
    "plt.grid(True); plt.xlabel('$\\hat{y}$'); plt.legend(); plt.title('Cross entropy loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To apply gradient descent, we need to know the gradient of the loss w.r.t. the parameters $\\vec{w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: Prove that for the cross entropy loss with binary logistic regression, it holds that:\n",
    "$$\n",
    "\\pderiv{\\ell(y,\\hat{y})}{\\vec{w}}= (\\hat{y}-y)\\vec{x}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Proof:\n",
    "\n",
    "First, we apply the chain-rule\n",
    "$$\n",
    "\\pderiv{\\ell(y,\\hat{y})}{\\vec{w}}=\\pderiv{\\ell}{\\hat{y}}\\cdot\\pderiv{\\hat{y}}{z}\\cdot\\pderiv{z}{\\vec{w}},\n",
    "$$\n",
    "where $z=\\vectr{w}\\vec{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now, just by definition,\n",
    "$$\n",
    "\\begin{align}\n",
    "\\pderiv{\\ell}{\\hat{y}}&=-\\frac{y}{\\hat{y}}+\\frac{1-y}{1-\\hat{y}}=\\frac{\\hat{y}-y}{\\hat{y}(1-\\hat{y})}\\\\\n",
    "\\pderiv{\\hat{y}}{z}&=\\frac{e^{-z}}{(1+e^{-z})^2}=\n",
    "\\frac{e^{-z}}{1+e^{-z}}\\cdot\\frac{1}{1+e^{-z}}=(1-\\sigma(z))\\sigma(z)=(1-\\hat{y})\\hat{y}\\\\\n",
    "\\pderiv{z}{\\vec{w}}&=\\vec{x}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 1: Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As a warm up exercise, let's see a quick example of implementing this algorithm and training it from scratch using just `numpy` (and a toy dataset from `sklearn`).\n",
    "\n",
    "This is a classic and very simple example of implementing and training a machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The `scikit-learn` library comes with a few [toy datasets](http://scikit-learn.org/stable/datasets/index.html#toy-datasets) that are fun to quickly train small models on.\n",
    "\n",
    "As an example we'll load the Wisconsin-breast cancer database:\n",
    "- 569 samples of cancer patients\n",
    "- 30 features: various properties of tumor cells extracted from images\n",
    "- 2 classes: Tumor is either [Benign or Malignant (שפיר או ממאיר)](https://www.verywellhealth.com/what-does-malignant-and-benign-mean-514240)\n",
    "\n",
    "<center><img src=\"https://www.verywellhealth.com/thmb/IFgBpbmhYCJdS4rvLACzX3Ukqsc=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/514240-article-img-malignant-vs-benign-tumor2111891f-54cc-47aa-8967-4cd5411fdb2f-5a2848f122fa3a0037c544be.png\" width=800 /></center>\n",
    "\n",
    "\n",
    "We'll apply the basic machine learning approach we saw above: binary logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features=30\n",
      "feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "target  names: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "ds_cancer = sklearn.datasets.load_breast_cancer()\n",
    "feature_names = ds_cancer.feature_names\n",
    "target_names = ds_cancer.target_names\n",
    "n_features = len(feature_names)\n",
    "\n",
    "print(f'{n_features=}')\n",
    "print(f'feature names: {feature_names}')\n",
    "print(f'target  names: {target_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (569, 30)\n",
      "y: (569,)\n"
     ]
    }
   ],
   "source": [
    "X, y = ds_cancer.data, ds_cancer.target\n",
    "n_samples = len(y)\n",
    "\n",
    "print(f'X: {X.shape}')\n",
    "print(f'y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>13.610</td>\n",
       "      <td>582.7</td>\n",
       "      <td>0.08625</td>\n",
       "      <td>0.05871</td>\n",
       "      <td>2.8610</td>\n",
       "      <td>0.014880</td>\n",
       "      <td>0.01465</td>\n",
       "      <td>35.27</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.981</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>1.5530</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.02659</td>\n",
       "      <td>19.54</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.180</td>\n",
       "      <td>458.7</td>\n",
       "      <td>0.02383</td>\n",
       "      <td>0.05677</td>\n",
       "      <td>1.1830</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.01447</td>\n",
       "      <td>32.84</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>9.876</td>\n",
       "      <td>298.3</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>0.06322</td>\n",
       "      <td>1.5280</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>0.01609</td>\n",
       "      <td>26.83</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.09749</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>10.490</td>\n",
       "      <td>336.1</td>\n",
       "      <td>0.02995</td>\n",
       "      <td>0.06481</td>\n",
       "      <td>2.3020</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0.02710</td>\n",
       "      <td>23.31</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.03203</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>13.110</td>\n",
       "      <td>530.2</td>\n",
       "      <td>0.20710</td>\n",
       "      <td>0.07692</td>\n",
       "      <td>2.4100</td>\n",
       "      <td>0.029120</td>\n",
       "      <td>0.01547</td>\n",
       "      <td>22.40</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.19860</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>11.640</td>\n",
       "      <td>412.5</td>\n",
       "      <td>0.07070</td>\n",
       "      <td>0.06520</td>\n",
       "      <td>2.1550</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.01565</td>\n",
       "      <td>29.26</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>12.360</td>\n",
       "      <td>466.7</td>\n",
       "      <td>0.02643</td>\n",
       "      <td>0.06066</td>\n",
       "      <td>0.8484</td>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.01251</td>\n",
       "      <td>27.49</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.08442</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>22.270</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>0.42640</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>10.0500</td>\n",
       "      <td>0.086680</td>\n",
       "      <td>0.03112</td>\n",
       "      <td>28.01</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>0.29100</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>11.340</td>\n",
       "      <td>396.5</td>\n",
       "      <td>0.05133</td>\n",
       "      <td>0.06529</td>\n",
       "      <td>1.5970</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>0.01568</td>\n",
       "      <td>29.15</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.08278</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean area  mean concavity  mean fractal dimension  \\\n",
       "100       13.610      582.7         0.08625                 0.05871   \n",
       "101        6.981      143.5         0.00000                 0.07818   \n",
       "102       12.180      458.7         0.02383                 0.05677   \n",
       "103        9.876      298.3         0.06154                 0.06322   \n",
       "104       10.490      336.1         0.02995                 0.06481   \n",
       "105       13.110      530.2         0.20710                 0.07692   \n",
       "106       11.640      412.5         0.07070                 0.06520   \n",
       "107       12.360      466.7         0.02643                 0.06066   \n",
       "108       22.270     1509.0         0.42640                 0.07039   \n",
       "109       11.340      396.5         0.05133                 0.06529   \n",
       "\n",
       "     perimeter error  compactness error  symmetry error  worst texture  \\\n",
       "100           2.8610           0.014880         0.01465          35.27   \n",
       "101           1.5530           0.010840         0.02659          19.54   \n",
       "102           1.1830           0.006098         0.01447          32.84   \n",
       "103           1.5280           0.021960         0.01609          26.83   \n",
       "104           2.3020           0.022190         0.02710          23.31   \n",
       "105           2.4100           0.029120         0.01547          22.40   \n",
       "106           2.1550           0.023100         0.01565          29.26   \n",
       "107           0.8484           0.010470         0.01251          27.49   \n",
       "108          10.0500           0.086680         0.03112          28.01   \n",
       "109           1.5970           0.015570         0.01568          29.15   \n",
       "\n",
       "     worst smoothness  worst concave points      CLASS  \n",
       "100            0.1265               0.11840  MALIGNANT  \n",
       "101            0.1584               0.00000     BENIGN  \n",
       "102            0.1123               0.07431     BENIGN  \n",
       "103            0.1559               0.09749     BENIGN  \n",
       "104            0.1219               0.03203     BENIGN  \n",
       "105            0.1862               0.19860  MALIGNANT  \n",
       "106            0.1688               0.12180     BENIGN  \n",
       "107            0.1184               0.08442     BENIGN  \n",
       "108            0.1701               0.29100  MALIGNANT  \n",
       "109            0.1699               0.08278     BENIGN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load into a pandas dataframe and show some samples\n",
    "y_names = np.full_like(y, target_names[0].upper(), dtype=target_names.dtype)\n",
    "y_names[y==1] = target_names[1].upper()\n",
    "\n",
    "df_cancer = pd.DataFrame(data=X, columns=ds_cancer.feature_names)\n",
    "df_cancer = df_cancer.assign(CLASS=y_names)\n",
    "df_cancer.iloc[100:110, 0::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: X=(398, 30) y=(398,)\n",
      "test : X=(171, 30) y=(171,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f'train: X={X_train.shape} y={y_train.shape}')\n",
    "print(f'test : X={X_test.shape} y={y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_X.shape=(30,), sigma_X.shape=(30,)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "\n",
    "# Note: each feature is standardized individually:\n",
    "mu_X = np.mean(X_train, axis=0) # (N, D) -> (D,)\n",
    "sigma_X = np.std(X_train, axis=0)\n",
    "\n",
    "# Note: Broadcasting (N, D) with (D,) -> (N, D)\n",
    "X_train_sc = (X_train - mu_X) / sigma_X \n",
    "\n",
    "# Note: Test set must be transformed identically to training set\n",
    "X_test_sc = (X_test - mu_X) / sigma_X\n",
    "\n",
    "print(f'{mu_X.shape=}, {sigma_X.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Implementation\n",
    "\n",
    "We'll implement based on the above definitions.\n",
    "\n",
    "The model will be implemented as a class with an API that conforms to the `sklearn` models, specifically see\n",
    "`sklearn`'s [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression(object):\n",
    "    def __init__(self, n_iter=100, learn_rate=0.1):\n",
    "        self.n_iter = n_iter\n",
    "        self.learn_rate = learn_rate\n",
    "        self._w = None\n",
    "        \n",
    "    def _add_bias(self, X: np.ndarray):\n",
    "        # Add a bias term column\n",
    "        ones_col = np.ones((X.shape[0], 1))\n",
    "        return np.hstack([ones_col, X])\n",
    "    \n",
    "    def predict_proba(self, X: np.ndarray, add_bias=True):\n",
    "        X = self._add_bias(X) if add_bias else X\n",
    "        \n",
    "        # Apply logistic model\n",
    "        z = np.dot(X, self.weights) # (N, D) * (D,)\n",
    "        return logistic(z) # shape (N,)\n",
    "    \n",
    "    def predict(self, X: np.ndarray):\n",
    "        proba = self.predict_proba(X)\n",
    "        \n",
    "        # Apply naive threshold of .5\n",
    "        return np.array(proba > .5, dtype=np.int)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        n, d = X.shape # X is (N, D), y is (N,)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._w = np.random.randn(d + 1) * 0.1\n",
    "        \n",
    "        Xb = self._add_bias(X)\n",
    "\n",
    "        # Training loop\n",
    "        self._losses = []\n",
    "        for i in range(self.n_iter):\n",
    "            # Predicted probabilities\n",
    "            y_hat = self.predict_proba(Xb, add_bias=False)\n",
    "            \n",
    "            # Pointwise loss\n",
    "            loss = -y.dot(np.log(y_hat)) - ((1 - y).dot(np.log(1 - y_hat)))\n",
    "            \n",
    "            # See Exercise for gradient derivation\n",
    "            loss_grad = 1/n * Xb.T.dot(y_hat - y)  # dl/dw: (D+1, N) * (N,)\n",
    "            \n",
    "            # Optimization step\n",
    "            self._w += -self.learn_rate * loss_grad\n",
    "            self._losses.append(loss)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        if self._w is None:\n",
    "            raise ValueError(\"Model is not fitted\")\n",
    "        return self._w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "lr_model = BinaryLogisticRegression(n_iter=500, learn_rate=0.01)\n",
    "lr_model.fit(X_train_sc, y_train)\n",
    "\n",
    "plt.plot(lr_model._losses, label='$L_{\\mathcal{S}}$');\n",
    "plt.xlabel('training iteration'); plt.legend(); plt.grid(True); plt.title('Train loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set accuracy: 96.98%\n",
      "test set accuracy: 95.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-99026b2ed7a5>:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return np.array(proba > .5, dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lr_model.predict(X_train_sc)\n",
    "train_acc = np.mean(y_train_pred == y_train)\n",
    "print(f'train set accuracy: {train_acc*100:.2f}%')\n",
    "\n",
    "y_test_pred = lr_model.predict(X_test_sc)\n",
    "test_acc = np.mean(y_test_pred == y_test)\n",
    "print(f'test set accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2: Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What if we have $C$ classes? Can we still use logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A naïve approach is to train $C$ binary logistic regression classifiers, for example in a One vs. Rest scheme,\n",
    "and then predict based on the classifier returning the greatest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One major drawback of this approach is that it doesn't model the probability distribution over the possible classes, $P_{\\vec{Y}|\\vec{X}}$. \n",
    "\n",
    "For example, a sample might be classified as class A with probability $0.8$ and class $B$ with $0.7$ since nothing constrains the different classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Softmax** is a function which can generate a probability distribution for our $C$ classes given raw prediction scores. It's defined as follows:\n",
    "\n",
    "$$\n",
    "\\mathrm{softmax}(\\vec{z}) = \\frac{e^{\\vec{z}}}{\\sum_{j=1}^{C} e^{z_j}}\n",
    "$$\n",
    "\n",
    "note that this is a vector valued, multivariate function. The exponent in the enumerator operates elementwise.\n",
    "\n",
    "The result of softmax is a vector with elements in $[0,1]$ that all sum to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The multiclass model\n",
    "\n",
    "Our model can now be defined as\n",
    "\n",
    "$$\\hat{\\vec{y}} = h(\\vec{x}) = \\mathrm{softmax}(\\mattr{W}\\vec{x}+\\vec{b})$$\n",
    "\n",
    "where,\n",
    "- $\\hat{\\vec{y}}$ is a $C\\times 1$ vector of class probabilities.\n",
    "- ${\\vec{x}}$ is a $D\\times 1$ sample.\n",
    "- $  {W}$ is a $D\\times C$ matrix representing the per-class weights.\n",
    "- $\\vec{b}$ is a per-class bias vector of length $C$.\n",
    "\n",
    "Probabilistic interpretation: $\\hat{y}_j = P(\\rvar{Y}=j|\\rvec{X}=\\vec{x})$.\n",
    "\n",
    "While not very powerful on it's own, this type of model is commonly found at the end of deep neural networks performing classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To train such a model we need our labels to also be singleton probability distributions instead of simply the number of the correct class.\n",
    "\n",
    "We'll transform our labels to a 1-hot encoded vector corresponding to a delta distribution.\n",
    "For example, if $y^i=j$ then we'll create\n",
    "$$\n",
    "\\vec{y}^i = [0,\\dots,0,\\underbrace{1}_{j\\mathrm{th\\ component}},0,\\dots,0]^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cross-Entropy loss\n",
    "\n",
    "After defing the 1-hot label vectors, the multiclass extension of the binary cross-entropy is straightforward:\n",
    "\n",
    "$$\n",
    "\\ell(\\vec{y}, \\hat{\\vec{y}}) = - \\vec{y} \\log(\\hat{\\vec{y}})\n",
    "$$\n",
    "\n",
    "Note that only the probability assigned to the correct class affects the loss.\n",
    "\n",
    "Minimizing this cross entropy can be interpreted as trying to move the probability distribution of model predictions towards the singleton distribution of the appropriate class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This time we'll tackle an image classification task, the MNIST database of handwritten digits.\n",
    "\n",
    "Today this is also considered a toy dataset, even though it was used in the past to benchmark classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import plot_utils\n",
    "\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the transforms that should be applied to each image in the dataset before returning it\n",
    "tf_ds = torchvision.transforms.ToTensor()\n",
    "\n",
    "batch_size = 64\n",
    "data_root = os.path.expanduser(\"~/.pytorch-datasets\")\n",
    "\n",
    "# Training and test datasets\n",
    "ds_train, ds_test = [\n",
    "    torchvision.datasets.MNIST(root=data_root, download=True, train=train, transform=tf_ds)   \n",
    "    for train in [True, False]\n",
    "]\n",
    "\n",
    "# Data loaders\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size, shuffle=True)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=len(ds_test))\n",
    "\n",
    "x0, y0 = ds_train[0]\n",
    "n_features = torch.numel(x0)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: torch.Size([1, 28, 28]), y0: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show first few samples\n",
    "print(f'x0: {x0.shape}, y0: {y0}')\n",
    "plot_utils.dataset_first_n(ds_train, 10, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that when training, we're actually working with **batches** of samples (we'll learn about SGD in the sebsequent lectures/tutorials):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0, y0 = next(iter(dl_train))\n",
    "x0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This time we'll use `pytorch` tensors and its [`autograd`](https://pytorch.org/docs/stable/autograd.html) functionality to implement our model.\n",
    "\n",
    "This means we wont have to implement any gradient calculations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, let's implement $\\mathrm{softmax}(\\cdot)$. We need a small numerical trick to prevent large numbers from exploding the exponentiation. You can verify that this doesn't influence the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z: Tensor) -> Tensor:\n",
    "    \"\"\" Softmax of z (N,C), a batch of class scores per sample \"\"\"\n",
    "\n",
    "    # normalization trick to prevent numerical instability:\n",
    "    # shift so that the highest class score (per sample) is 0\n",
    "    zmax, _ = torch.max(z, dim=1, keepdim=True)\n",
    "    z = z - zmax # note broadcasting: (N,C) - (N,1)\n",
    "    \n",
    "    exp_z = torch.exp(z) # (N, C)\n",
    "    sum_exp = torch.sum(exp_z, dim=1, keepdim=True) # (N, 1)\n",
    "    return exp_z / sum_exp # probabilities, (N,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's test our softmax and calculate its derivative with `autograd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6005, 0.0097, 0.3898],\n",
       "        [0.3947, 0.1850, 0.4203],\n",
       "        [0.0709, 0.0711, 0.8580],\n",
       "        [0.1064, 0.7703, 0.1233]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randn(size=(4,3), requires_grad=True)\n",
    "y = softmax(z)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = softmax(z)\n",
    "L = torch.sum(y) # scalar function of z \n",
    "\n",
    "# Calculate gradient: dL/dz\n",
    "torch.autograd.grad(L, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Instead of calling `autograd.grad()` directly with specific input tensors, `pytorch` provides us with a way to calculate the derivative of a tensor w.r.t. all the tensors which are **leaves** in it's computation graph ($\\vec{z}$ ini this case).\n",
    "\n",
    "This can be done by calling `.backward()` on a scalar tensor.\n",
    "As a result, the `.grad` property of leaf tensors will be populated with the gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = softmax(z)\n",
    "L = torch.sum(y) # scalar function of z \n",
    "L.backward()     # Calculate derivative w.r.t. all leaves\n",
    "z.grad           # The leaf z will have its .grad populated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here's the resulting computation graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"140pt\" height=\"490pt\"\n",
       " viewBox=\"0.00 0.00 140.00 490.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 486)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-486 136,-486 136,4 -4,4\"/>\n",
       "<!-- 140189153109056 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140189153109056</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 140187474916736 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140187474916736</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n",
       "</g>\n",
       "<!-- 140187474916736&#45;&gt;140189153109056 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140187474916736&#45;&gt;140189153109056</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n",
       "</g>\n",
       "<!-- 140187474916640 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140187474916640</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">DivBackward0</text>\n",
       "</g>\n",
       "<!-- 140187474916640&#45;&gt;140187474916736 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140187474916640&#45;&gt;140187474916736</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n",
       "</g>\n",
       "<!-- 140187474917024 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140187474917024</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"92,-251 9,-251 9,-232 92,-232 92,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">ExpBackward</text>\n",
       "</g>\n",
       "<!-- 140187474917024&#45;&gt;140187474916640 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140187474917024&#45;&gt;140187474916640</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M46.39,-231.88C42.44,-223.09 36.76,-208.94 34.5,-196 31.79,-180.43 36.74,-163.03 41.84,-150.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.13,-151.6 45.98,-141.04 38.73,-148.76 45.13,-151.6\"/>\n",
       "</g>\n",
       "<!-- 140187474918224 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140187474918224</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-196 43,-196 43,-177 132,-177 132,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SumBackward1</text>\n",
       "</g>\n",
       "<!-- 140187474917024&#45;&gt;140187474918224 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140187474917024&#45;&gt;140187474918224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.61,-231.75C61.78,-224.34 69.35,-213.5 75.69,-204.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.65,-206.29 81.5,-196.09 72.91,-202.29 78.65,-206.29\"/>\n",
       "</g>\n",
       "<!-- 140187474916928 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140187474916928</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-306 6,-306 6,-287 95,-287 95,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140187474916928&#45;&gt;140187474917024 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140187474916928&#45;&gt;140187474917024</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.75C50.5,-279.8 50.5,-269.85 50.5,-261.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.09 50.5,-251.09 47,-261.09 54,-261.09\"/>\n",
       "</g>\n",
       "<!-- 140187474917120 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140187474917120</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-416 0,-416 0,-397 101,-397 101,-416\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140187474917120&#45;&gt;140187474916928 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140187474917120&#45;&gt;140187474916928</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M46.39,-396.88C42.44,-388.09 36.76,-373.94 34.5,-361 31.79,-345.43 36.74,-328.03 41.84,-315.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.13,-316.6 45.98,-306.04 38.73,-313.76 45.13,-316.6\"/>\n",
       "</g>\n",
       "<!-- 140187474916592 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140187474916592</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-361 43,-361 43,-342 132,-342 132,-361\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MaxBackward0</text>\n",
       "</g>\n",
       "<!-- 140187474917120&#45;&gt;140187474916592 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140187474917120&#45;&gt;140187474916592</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.61,-396.75C61.78,-389.34 69.35,-378.5 75.69,-369.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.65,-371.29 81.5,-361.09 72.91,-367.29 78.65,-371.29\"/>\n",
       "</g>\n",
       "<!-- 140187535784064 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140187535784064</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-482 21,-482 21,-452 80,-452 80,-482\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-470\" font-family=\"monospace\" font-size=\"10.00\">z</text>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\"> (4, 3)</text>\n",
       "</g>\n",
       "<!-- 140187535784064&#45;&gt;140187474917120 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140187535784064&#45;&gt;140187474917120</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-451.84C50.5,-444.21 50.5,-434.7 50.5,-426.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-426.27 50.5,-416.27 47,-426.27 54,-426.27\"/>\n",
       "</g>\n",
       "<!-- 140187474916592&#45;&gt;140187474916928 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140187474916592&#45;&gt;140187474916928</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81.39,-341.75C76.22,-334.34 68.65,-323.5 62.31,-314.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.09,-312.29 56.5,-306.09 59.35,-316.29 65.09,-312.29\"/>\n",
       "</g>\n",
       "<!-- 140187474918224&#45;&gt;140187474916640 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140187474918224&#45;&gt;140187474916640</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81.39,-176.75C76.22,-169.34 68.65,-158.5 62.31,-149.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.09,-147.29 56.5,-141.09 59.35,-151.29 65.09,-147.29\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f7ff44777f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "torchviz.make_dot(L, params=dict(z=z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The next ingredient of the solution is the cross-entropy loss function.\n",
    "\n",
    "Recall that we need to encode our ground-truth labels as one-hot vectors to apply the multiclass cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y: Tensor, y_hat: Tensor):\n",
    "    \"\"\"\n",
    "    y_hat (N,C) is a batch of probabilities\n",
    "    y (N, C) is onehot ground-truth labels\n",
    "    \"\"\"\n",
    "    return torch.sum( - y * torch.log(y_hat + 1e-6) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def onehot(y: Tensor, n_classes: int) -> Tensor:\n",
    "    \"\"\" Encodes y of shape (N,) as one-hot of shape (N,C) \"\"\"\n",
    "    \n",
    "    y = y.reshape(-1, 1) # Reshape y to (N,1)\n",
    "    zeros = torch.zeros(size=(len(y), n_classes), dtype=torch.float32) # (N,C)\n",
    "    ones = torch.ones_like(y, dtype=torch.float32)\n",
    "    \n",
    "    # scatter: put items from 'src' into 'dest' at indices correspondnig to 'index' along 'dim'\n",
    "    y_onehot = torch.scatter(zeros, dim=1, index=y, src=ones)\n",
    "    \n",
    "    return y_onehot # result has shape (N, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot(torch.tensor([1, 3, 5, 0]), n_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our model itself will just hold the parameters $\\mat{W}$ and $\\vec{b}$ and apply them to an input batch $\\mat{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class MCLogisticRegression(object):\n",
    "    def __init__(self, n_features: int, n_classes: int):\n",
    "        # Define our parameter tensors: notice that now W and b are separate\n",
    "        # Specify we want to track their gradients with autograd\n",
    "        self.W = torch.randn(n_features, n_classes, requires_grad=True)\n",
    "        self.b = torch.randn(n_classes, requires_grad=True)\n",
    "        self.params = [self.W, self.b]\n",
    "    \n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "    def forward(self, X: Tensor):\n",
    "        \"\"\"\n",
    "        X (N, D) contains a batch of samples\n",
    "        output (N, C) is a batch of class probabilities\n",
    "        \"\"\"\n",
    "        # X is (N, D), W is (D, C), b is (C,)\n",
    "        z = torch.mm(X, self.W) + self.b\n",
    "        y_hat = softmax(z)\n",
    "        return y_hat # (N, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try out the model and loss on the first batch.\n",
    "\n",
    "Note that we naïvely treat each pixel as a separate feature. We'll learn how to properly work with images in a future tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0_flat: torch.Size([64, 784])\n",
      "y0_onehot: torch.Size([64, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MCLogisticRegression(n_features, n_classes)\n",
    "\n",
    "# Flatten images and convert labels to onehot\n",
    "x0_flat = x0.reshape(-1, n_features)\n",
    "y0_onehot =  onehot(y0, n_classes)\n",
    "\n",
    "print(f'x0_flat: {x0_flat.shape}')\n",
    "print(f'y0_onehot: {y0_onehot.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(652.7525, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Forward pass and compute loss\n",
    "y0_hat = model(x0_flat)\n",
    "loss = cross_entropy_loss(y0_onehot, y0_hat)\n",
    "print('loss = ', loss)\n",
    "\n",
    "# Backward pass to populate .grad on leaf nodes\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since we specified `require_grad=True` for our model parameters, every operation performed on these tensors is recorded, and a **computation graph** can be built, which included the model and loss calculation.\n",
    "Notice that the **leaves** in this graph are our parameters $\\mat{W}$ and $\\vec{b}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"216pt\" height=\"776pt\"\n",
       " viewBox=\"0.00 0.00 216.00 776.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 772)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-772 212,-772 212,4 -4,4\"/>\n",
       "<!-- 140189153307776 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140189153307776</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"130.5,-31 76.5,-31 76.5,0 130.5,0 130.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 140189157199824 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140189157199824</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-86 59,-86 59,-67 148,-67 148,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n",
       "</g>\n",
       "<!-- 140189157199824&#45;&gt;140189153307776 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>140189157199824&#45;&gt;140189153307776</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-66.79C103.5,-60.07 103.5,-50.4 103.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-41.19 103.5,-31.19 100,-41.19 107,-41.19\"/>\n",
       "</g>\n",
       "<!-- 140189156423568 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140189156423568</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-141 59,-141 59,-122 148,-122 148,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140189156423568&#45;&gt;140189157199824 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140189156423568&#45;&gt;140189157199824</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-121.75C103.5,-114.8 103.5,-104.85 103.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-96.09 103.5,-86.09 100,-96.09 107,-96.09\"/>\n",
       "</g>\n",
       "<!-- 140189156422560 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140189156422560</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"145,-196 62,-196 62,-177 145,-177 145,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">LogBackward</text>\n",
       "</g>\n",
       "<!-- 140189156422560&#45;&gt;140189156423568 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140189156422560&#45;&gt;140189156423568</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-176.75C103.5,-169.8 103.5,-159.85 103.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-151.09 103.5,-141.09 100,-151.09 107,-151.09\"/>\n",
       "</g>\n",
       "<!-- 140189156425248 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140189156425248</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-251 59,-251 59,-232 148,-232 148,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140189156425248&#45;&gt;140189156422560 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140189156425248&#45;&gt;140189156422560</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-231.75C103.5,-224.8 103.5,-214.85 103.5,-206.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-206.09 103.5,-196.09 100,-206.09 107,-206.09\"/>\n",
       "</g>\n",
       "<!-- 140189156425152 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140189156425152</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-306 59,-306 59,-287 148,-287 148,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">DivBackward0</text>\n",
       "</g>\n",
       "<!-- 140189156425152&#45;&gt;140189156425248 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140189156425152&#45;&gt;140189156425248</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-286.75C103.5,-279.8 103.5,-269.85 103.5,-261.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-261.09 103.5,-251.09 100,-261.09 107,-261.09\"/>\n",
       "</g>\n",
       "<!-- 140187535878656 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140187535878656</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"145,-416 62,-416 62,-397 145,-397 145,-416\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">ExpBackward</text>\n",
       "</g>\n",
       "<!-- 140187535878656&#45;&gt;140189156425152 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140187535878656&#45;&gt;140189156425152</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99.39,-396.88C95.44,-388.09 89.76,-373.94 87.5,-361 84.79,-345.43 89.74,-328.03 94.84,-315.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"98.13,-316.6 98.98,-306.04 91.73,-313.76 98.13,-316.6\"/>\n",
       "</g>\n",
       "<!-- 140187535879712 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>140187535879712</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"185,-361 96,-361 96,-342 185,-342 185,-361\"/>\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">SumBackward1</text>\n",
       "</g>\n",
       "<!-- 140187535878656&#45;&gt;140187535879712 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>140187535878656&#45;&gt;140187535879712</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.61,-396.75C114.78,-389.34 122.35,-378.5 128.69,-369.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131.65,-371.29 134.5,-361.09 125.91,-367.29 131.65,-371.29\"/>\n",
       "</g>\n",
       "<!-- 140187535877936 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140187535877936</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-471 59,-471 59,-452 148,-452 148,-471\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140187535877936&#45;&gt;140187535878656 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140187535877936&#45;&gt;140187535878656</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-451.75C103.5,-444.8 103.5,-434.85 103.5,-426.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-426.09 103.5,-416.09 100,-426.09 107,-426.09\"/>\n",
       "</g>\n",
       "<!-- 140187535879664 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140187535879664</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-581 59,-581 59,-562 148,-562 148,-581\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-569\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140187535879664&#45;&gt;140187535877936 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140187535879664&#45;&gt;140187535877936</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99.39,-561.88C95.44,-553.09 89.76,-538.94 87.5,-526 84.79,-510.43 89.74,-493.03 94.84,-480.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"98.13,-481.6 98.98,-471.04 91.73,-478.76 98.13,-481.6\"/>\n",
       "</g>\n",
       "<!-- 140187535878512 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>140187535878512</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"185,-526 96,-526 96,-507 185,-507 185,-526\"/>\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\">MaxBackward0</text>\n",
       "</g>\n",
       "<!-- 140187535879664&#45;&gt;140187535878512 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>140187535879664&#45;&gt;140187535878512</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.61,-561.75C114.78,-554.34 122.35,-543.5 128.69,-534.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131.65,-536.29 134.5,-526.09 125.91,-532.29 131.65,-536.29\"/>\n",
       "</g>\n",
       "<!-- 140187535842368 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140187535842368</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"89,-636 12,-636 12,-617 89,-617 89,-636\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-624\" font-family=\"monospace\" font-size=\"10.00\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140187535842368&#45;&gt;140187535879664 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140187535842368&#45;&gt;140187535879664</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.25,-616.75C66.97,-609.03 78.4,-597.6 87.72,-588.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.31,-590.64 94.91,-581.09 85.36,-585.69 90.31,-590.64\"/>\n",
       "</g>\n",
       "<!-- 140187535842656 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140187535842656</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-696.5 0,-696.5 0,-677.5 101,-677.5 101,-696.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-684.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140187535842656&#45;&gt;140187535842368 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140187535842656&#45;&gt;140187535842368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-677.37C50.5,-669.25 50.5,-656.81 50.5,-646.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-646.17 50.5,-636.17 47,-646.17 54,-646.17\"/>\n",
       "</g>\n",
       "<!-- 140189153307712 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140189153307712</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"89,-768 12,-768 12,-738 89,-738 89,-768\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-756\" font-family=\"monospace\" font-size=\"10.00\">W</text>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-745\" font-family=\"monospace\" font-size=\"10.00\"> (784, 10)</text>\n",
       "</g>\n",
       "<!-- 140189153307712&#45;&gt;140187535842656 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140189153307712&#45;&gt;140187535842656</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-737.8C50.5,-728.7 50.5,-716.79 50.5,-706.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-706.84 50.5,-696.84 47,-706.84 54,-706.84\"/>\n",
       "</g>\n",
       "<!-- 140187535840640 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140187535840640</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-636 107,-636 107,-617 208,-617 208,-636\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.5\" y=\"-624\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140187535840640&#45;&gt;140187535879664 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140187535840640&#45;&gt;140187535879664</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.58,-616.75C140.72,-609.03 129.07,-597.6 119.58,-588.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"121.84,-585.6 112.25,-581.09 116.94,-590.59 121.84,-585.6\"/>\n",
       "</g>\n",
       "<!-- 140189153307520 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140189153307520</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"184.5,-702 130.5,-702 130.5,-672 184.5,-672 184.5,-702\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.5\" y=\"-690\" font-family=\"monospace\" font-size=\"10.00\">b</text>\n",
       "<text text-anchor=\"middle\" x=\"157.5\" y=\"-679\" font-family=\"monospace\" font-size=\"10.00\"> (10)</text>\n",
       "</g>\n",
       "<!-- 140189153307520&#45;&gt;140187535840640 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140189153307520&#45;&gt;140187535840640</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.5,-671.84C157.5,-664.21 157.5,-654.7 157.5,-646.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"161,-646.27 157.5,-636.27 154,-646.27 161,-646.27\"/>\n",
       "</g>\n",
       "<!-- 140187535878512&#45;&gt;140187535877936 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140187535878512&#45;&gt;140187535877936</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M134.39,-506.75C129.22,-499.34 121.65,-488.5 115.31,-479.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.09,-477.29 109.5,-471.09 112.35,-481.29 118.09,-477.29\"/>\n",
       "</g>\n",
       "<!-- 140187535879712&#45;&gt;140189156425152 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>140187535879712&#45;&gt;140189156425152</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M134.39,-341.75C129.22,-334.34 121.65,-323.5 115.31,-314.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.09,-312.29 109.5,-306.09 112.35,-316.29 118.09,-312.29\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f8054ea8eb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "torchviz.make_dot(loss, params=dict(W=model.W, b=model.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This graph is what allows efficient implementation of the **back-propagation** algorithm which you'll learn about in the next lecture.\n",
    "\n",
    "By calling `.backward()` from the final loss tensor, pytorch automatically populated the `.grad` property of all leaves in this graph, without us having to explicitly specify them (`W` and `b`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The optimization will be as before, but now we'll take the gradients from the `grad` property of our parameter tensors.\n",
    "\n",
    "Therefore, the optimizer (in this case just a funcion) only needs access to the parameter tensors from the model.\n",
    "Later you'll see that `pytorch`'s `Optimizer` classes work in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sgd_optimizer(params: [Tensor, ...], learn_rate: float):\n",
    "    # params is a list of Tensors\n",
    "    with torch.autograd.no_grad(): # Don't track gradients for this operation\n",
    "        for param in params:\n",
    "            param -= learn_rate * param.grad\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Inference and prediction accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy pre-training: 8.87%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_accuracy(dataloader, model, max_batches=None):\n",
    "    n_correct = 0.\n",
    "    n_total = 0.\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        X = X.reshape(-1, n_features) # flatten images into vectors\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.autograd.no_grad():\n",
    "            y_hat = model(X)\n",
    "        \n",
    "        predictions = torch.argmax(y_hat, dim=1)\n",
    "        n_correct += torch.sum(predictions == y).type(torch.float32)\n",
    "        n_total += X.shape[0]\n",
    "        \n",
    "        if max_batches and i+1 >= max_batches:\n",
    "            break\n",
    "        \n",
    "    return (n_correct / n_total).item()\n",
    "\n",
    "test_set_acc = evaluate_accuracy(dl_test, MCLogisticRegression(n_features, n_classes))\n",
    "print(f'Test set accuracy pre-training: {test_set_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The training loop\n",
    "\n",
    "This is a crucial part of any ML pipeline where model parameters get updated iteratively.\n",
    "\n",
    "One pass over the entire training data is called an **epoch**.\n",
    "When using `pytorch`, your training loop will generally contain the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each epoch:\n",
    "    - Split training data into batches\n",
    "    - For each batch\n",
    "        - Forward pass: Compute predictions and build computation graph\n",
    "        - Calculate loss\n",
    "        - Set existing gradients to zero\n",
    "        - Backward pass: Use back-propagation algorithm to calculate the gradients\n",
    "        - Optimization step: Use the gradients to update the parameters\n",
    "    - Evaluate accuracy on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define some training hyper-parameters\n",
    "epochs = 10\n",
    "max_batches = 50  # limit batches so training is fast (just as a demo)\n",
    "learn_rate = .005\n",
    "num_samples = len(ds_train)\n",
    "\n",
    "# Instantiate the model we'll train\n",
    "model = MCLogisticRegression(n_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Avg Loss: 0.272, Train Acc: 54.37, Test Acc: 52.99\n",
      "Epoch 1. Avg Loss: 0.120, Train Acc: 66.22, Test Acc: 66.92\n",
      "Epoch 2. Avg Loss: 0.091, Train Acc: 72.75, Test Acc: 73.01\n",
      "Epoch 3. Avg Loss: 0.073, Train Acc: 77.06, Test Acc: 76.22\n",
      "Epoch 4. Avg Loss: 0.060, Train Acc: 77.44, Test Acc: 78.31\n",
      "Epoch 5. Avg Loss: 0.055, Train Acc: 78.84, Test Acc: 79.93\n",
      "Epoch 6. Avg Loss: 0.056, Train Acc: 80.41, Test Acc: 81.58\n",
      "Epoch 7. Avg Loss: 0.050, Train Acc: 80.03, Test Acc: 82.57\n",
      "Epoch 8. Avg Loss: 0.047, Train Acc: 83.66, Test Acc: 83.07\n",
      "Epoch 9. Avg Loss: 0.046, Train Acc: 83.03, Test Acc: 83.23\n"
     ]
    }
   ],
   "source": [
    "# Epoch: traverse all samples\n",
    "for e in range(epochs):\n",
    "    cumulative_loss = 0\n",
    "\n",
    "    # Loop over randdom batches of training data\n",
    "    for i, (X, y) in enumerate(dl_train):\n",
    "        \n",
    "        X = X.reshape(-1, n_features)\n",
    "        y_onehot = onehot(y, n_classes)\n",
    "        \n",
    "        # Forward pass: predictions and loss\n",
    "        y_hat = model(X)\n",
    "        loss = cross_entropy_loss(y_onehot, y_hat)\n",
    "        \n",
    "        # Backward pass: calculate gradients \n",
    "        loss.backward() \n",
    "        \n",
    "        # Update model using the calculated gradients\n",
    "        sgd_optimizer(model.params, learn_rate)\n",
    "        \n",
    "        cumulative_loss += loss.item()\n",
    "        if i+1 > max_batches:\n",
    "            break\n",
    "\n",
    "    # Evaluation\n",
    "    test_accuracy = evaluate_accuracy(dl_test, model, max_batches)\n",
    "    train_accuracy = evaluate_accuracy(dl_train, model, max_batches)\n",
    "    \n",
    "    avg_loss = cumulative_loss/num_samples\n",
    "    print(f\"Epoch {e}. Avg Loss: {avg_loss:.3f}, Train Acc: {train_accuracy*100:.2f}, Test Acc: {test_accuracy*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Final notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is a very naive implementation, for example because\n",
    "    - We didn't treat the images properly.\n",
    "    - We didn't include any regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- PyTorch provides many functions and classes that we could have used, for example:\n",
    "  - Perceptron fully connected layer with model parameters\n",
    "  - Softmax\n",
    "  - SGD and many other optimizers\n",
    "  - Cross entropy loss\n",
    "  \n",
    "  however the purpose here was to show an (almost) from-scratch implementation using only tensors,\n",
    "  in order to see whats \"under the hood\" (more or less) of the PyTorch functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further reading**<br>\n",
    "[Evaluation Metrics for Classification Models](https://www.analyticsvidhya.com/blog/2020/10/how-to-choose-evaluation-metrics-for-classification-model/)<br>\n",
    "[google explain imbalanced data](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data?fbclid=IwAR1v65XxQcl_3lb9kSh5WWs_-TWad4tyGoc_kWUP6eHxoI4m7JXeHLqAaFc)<br>\n",
    "[Deal with imbalanced data](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18)<br>\n",
    "[Fairness in ML book](http://www.fairmlbook.org)<br>\n",
    "[Fairness methods review](https://arxiv.org/abs/2012.15816)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Credits**\n",
    "\n",
    "This tutorial based on Technion IIT cs-236781 tutorial that written by [Aviv A. Rosenberg](https://avivr.net)\n",
    "And modeified by Moshe Kimhi.<br>\n",
    "\n",
    "Some images in this tutorial were taken and/or adapted from the following sources:\n",
    "- Fundamentals of Deep Learning, Nikhil Buduma, Oreilly 2017"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
